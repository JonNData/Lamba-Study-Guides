{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Nguyen_LS_DS_Unit_4_Sprint_Challenge_3_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nteract": {
      "version": "0.21.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonNData/Lamba-Study-Guides/blob/master/Nguyen_LS_DS_Unit_4_Sprint_Challenge_3_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt0vUPyBt7kk",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime locally, on AWS SageMaker, on Colab or on a comparable environment. If something is running longer, double check your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for object detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe a use case for an autoencoder\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - LSTMSs\n",
        "\n",
        "Use a LSTM to fit a multi-class classification model on Reuters news articles to distinguish topics of articles. The data is already encoded properly for use in a LSTM model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well as the LSTM code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "96d9edfb-b307-4423-9583-6c5dc946bfb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {}
      },
      "source": [
        "# Do not change this line. You need the +1 for some reason. \n",
        "max_features = len(word_index.values()) + 1\n",
        "\n",
        "# TODO - your code!\n",
        "#len(word_index)\n",
        "maxlen = 100\n",
        "batch_size = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIbLXTpyvty7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2518cc13-3b81-4bf4-c212-9f6ae7d10966"
      },
      "source": [
        "X_train, y_train"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([list([1, 248, 409, 166, 265, 1537, 1662, 8, 24, 4, 1222, 2771, 7, 227, 236, 40, 85, 944, 10, 531, 176, 8, 4, 176, 1613, 24, 1662, 297, 5157, 6, 10, 103, 5, 231, 215, 8, 7, 2889, 6, 10, 1202, 69, 4, 1222, 329, 2771, 24, 944, 23, 944, 1662, 40, 2509, 1592, 907, 69, 4, 113, 997, 762, 2539, 7, 227, 236, 17, 12]),\n",
              "        list([1, 4665, 1183, 413, 381, 7, 1134, 1664, 62, 729, 7, 4, 121, 273, 93, 109, 28, 2115, 72, 11, 428, 4, 387, 989, 558, 3956, 8, 7, 25, 1213, 427, 1969, 223, 4, 213, 5, 387, 580, 8, 1145, 413, 62, 410, 451, 18, 428, 7, 4, 121, 6, 3106, 19, 11, 428, 9, 1283, 317, 65, 413, 138, 59, 12, 11, 428, 6, 6118, 63, 11, 4, 3956, 8, 3640, 1183, 413, 202, 251, 18, 428, 6, 546, 19, 11, 428, 9, 317, 65, 413, 7, 4, 1721, 427, 409, 7145, 138, 19, 19, 11, 428, 6, 3843, 70, 11, 4, 135, 5, 137, 317, 1833, 542, 9, 7145, 413, 138, 72, 47, 11, 428, 6, 19, 5106, 19, 16, 8, 17, 12]),\n",
              "        list([1, 56, 14065, 65, 9, 249, 149, 8, 4, 347, 5, 25, 65, 9, 249, 282, 333, 27, 258, 20, 6, 644, 59, 11, 15, 22, 653, 32, 11, 15, 257, 28, 29, 153, 105, 519, 6, 42, 1436, 7233, 14065, 8, 16, 40, 282, 5, 32, 47, 11, 428, 5, 65, 9, 659, 249, 3264, 9, 934, 32, 35, 1396, 983, 5, 659, 249, 7, 788, 388, 20, 324, 56, 26262, 705, 149, 40, 342, 282, 5, 2639, 18, 428, 5, 65, 9, 19, 59, 10637, 5, 659, 249, 31, 10, 143, 347, 5, 32, 32, 11, 15, 14065, 8, 17, 12]),\n",
              "        ...,\n",
              "        list([1, 4, 60, 5, 794, 8, 16, 1106, 4, 239, 76, 31, 581, 444, 5, 69, 83, 11, 167, 52, 2298, 4, 797, 135, 444, 145, 6, 126, 3998, 11, 167, 9, 1481, 31, 25, 408, 5, 10, 445, 11, 167, 1264, 17, 12]),\n",
              "        list([1, 22508, 81, 8, 16, 369, 6, 223, 46, 13, 25, 383, 448, 99, 98, 6, 153, 252, 124, 208, 6, 624, 84, 404, 963, 6, 10, 73, 21238, 23751, 9, 1417, 21315, 247, 290, 504, 9, 186, 209, 5833, 148, 1910, 4, 2801, 5, 4, 29, 195, 3855, 26171, 118, 215, 17, 12]),\n",
              "        list([1, 37, 38, 342, 4089, 114, 5868, 107, 4, 78, 441, 55, 2418, 6, 1133, 10, 664, 66, 613, 519, 6, 10, 883, 2021, 27, 78, 15479, 396, 256, 903, 1520, 4, 15883, 869, 5, 537, 9, 4, 23528, 869, 5, 4632, 8, 6315, 4, 1004, 725, 21, 2384, 3153, 66, 41, 1318, 286, 190, 51, 15883, 265, 1850, 12137, 152, 4, 78, 6448, 1454, 12256, 66, 1704, 55, 768, 45, 6300, 652, 10, 73, 120, 4, 214, 212, 9, 392, 1760, 2384, 3153, 66, 1643, 69, 1340, 35, 15, 54, 29, 57, 85, 641, 332, 224, 54, 252, 21, 10, 613, 6, 153, 4, 804, 66, 2003, 1004, 164, 125, 78, 190, 4, 37, 38, 592, 10, 2761, 21, 4, 332, 5, 540, 19, 51, 286, 1930, 57, 8, 42, 120, 23, 328, 618, 1904, 6259, 1290, 12137, 8, 107, 129, 613, 23, 625, 1824, 66, 4089, 114, 11088, 161, 5, 1691, 694, 21, 195, 490, 6, 2897, 66, 1653, 95, 3876, 9, 52, 114, 870, 126, 342, 66, 1720, 36, 506, 392, 23, 900, 127, 205, 7, 25, 2576, 182, 50, 114, 592, 7297, 21, 4, 2548, 1824, 664, 66, 7, 37, 38, 9, 342, 8717, 9, 1373, 12137, 75, 8, 4, 342, 106, 23, 4697, 6, 10, 8312, 5, 168, 23635, 50, 114, 3616, 37, 38, 162, 6, 392, 10, 664, 66, 613, 2335, 27, 195, 490, 9, 591, 262, 4519, 5545, 41, 500, 73, 236, 13, 392, 9, 2070, 25, 422, 6, 1864, 1789, 5, 2002, 50, 41, 75, 444, 16, 6383, 162, 1338, 36, 8, 16, 41, 75, 148, 4, 851, 232, 247, 5, 286, 190, 12137, 8, 4, 2316, 5, 10, 613, 209, 30, 6, 153, 137, 725, 541, 83, 206, 246, 1185, 21, 162, 306, 1001, 13, 66, 7, 469, 9, 1118, 153, 2939, 21, 106, 6043, 9, 1541, 1412, 6, 2035, 66, 3036, 17, 12])],\n",
              "       dtype=object), array([19, 41, 16, ..., 19,  3, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdDWt9NyvDvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NcsD1n2uSlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Guess we'll pad these suckas\n",
        "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYmP3xk71fFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6ee6b47d-d92c-4ba6-b94e-a8fb14c0c992"
      },
      "source": [
        "x_train, y_train"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1662,  297, 5157, ...,  236,   17,   12],\n",
              "        [  65,  413,    7, ...,    8,   17,   12],\n",
              "        [ 659,  249,    7, ...,    8,   17,   12],\n",
              "        ...,\n",
              "        [ 794,    8,   16, ..., 1264,   17,   12],\n",
              "        [  98,    6,  153, ...,  215,   17,   12],\n",
              "        [   4, 2316,    5, ..., 3036,   17,   12]], dtype=int32),\n",
              " array([19, 41, 16, ..., 19,  3, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpavIsRbO9Oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.utils import to_categorical\n",
        "# y_train_binary = to_categorical(y_train)\n",
        "# y_test_binary = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSHhhharu9WU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "# Need this to flatten it to the apt shape\n",
        "model.add(Embedding(max_features, 128))\n",
        "# 128 specified by papers/industry. Dropout and recurrent_dropout set our forget params\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(len(y_train), activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edu_wF7BxMWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "362cdaee-3936-4cc8-a39d-4637ec651705"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=2,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/2\n",
            "8982/8982 [==============================] - 176s 20ms/step - loss: 2.4123 - accuracy: 0.3845 - val_loss: 1.7201 - val_accuracy: 0.5583\n",
            "Epoch 2/2\n",
            "8982/8982 [==============================] - 179s 20ms/step - loss: 1.6407 - accuracy: 0.5926 - val_loss: 1.4823 - val_accuracy: 0.6469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f3ffd21df98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz-60a-6SmO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "55e74d96-5d04-4435-8a71-9c6db9b1ecd5"
      },
      "source": [
        "# Results report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "epoch_count = range(1,3)\n",
        "\n",
        "plt.plot(epoch_count , model.history.history['accuracy'], 'p-')\n",
        "plt.plot(epoch_count , model.history.history['val_accuracy'], 'cyan')\n",
        "plt.legend(['Training accuracy', 'Validation accuracy'])\n",
        "plt.show();\n",
        "print('Validation Accuracy:', model.history.history['val_accuracy'])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxV1bn/8c9DmAcZgoxhCJgwExIOkziAiKIiFEUEnJBWcMDx1ta2Vr3a+rOtIDiAIijq9RZrq4i3WgkgiqJImFSCZCJCmAkQAiFken5/7JPkJAQ4kJOcIc/79eIFZw/nrA3hm5W1116PqCrGGGNCVy1/N8AYY0zVsqA3xpgQZ0FvjDEhzoLeGGNCnAW9McaEuNr+bkB5LVu21M6dO/u7GcYYE1TWr19/UFUvrGhfwAV9586dSUhI8HczjDEmqIjIz6fbZ0M3xhgT4izojTEmxFnQG2NMiPNqjF5ERgFzgDBggao+V8ExE4CnAAU2q+pk9/ZC4Af3YTtUdcy5NjI/P5+MjAxyc3PP9VQTourXr09ERAR16tTxd1OMCXhnDXoRCQNeAUYCGcA6EVmqqokex0QBvwOGquphEWnl8RYnVLVfZRqZkZFBkyZN6Ny5MyJSmbcyIUBVyczMJCMjg8jISH83x5iA583QzUAgRVXTVDUPWAyMLXfMXcArqnoYQFX3+7KRubm5hIeHW8gbAESE8PBw+wnPGC95E/TtgZ0erzPc2zxFA9Ei8rWIfOse6ilWX0QS3Nt/UdEHiMg09zEJBw4cqLARFvLGk309GOM9X82jrw1EAcOACOBLEemjqkeATqq6S0S6ACtF5AdVTfU8WVXnA/MBXC6XrZtsjKkxCoAfgW9wet7Tq+AzvOnR7wI6eLyOcG/zlAEsVdV8Vd0OJOEEP6q6y/17GrAKiK1km6tdZmYm/fr1o1+/frRp04b27duXvM7LyzvjuQkJCTzwwANn/YyLL77YV801xgSwvcAS4DGcnnFTnFC8F1hURZ/pTY9+HRAlIpE4AT8RmFzumCXAJOBNEWmJM5STJiLNgRxVPenePhT4q89afxqFRcrCr9KYuyqVe4d15ZeXdCGs1vn/qB8eHs6mTZsAeOqpp2jcuDG//vWvS/YXFBRQu3bFf5UulwuXy3XWz1izZs15t89fCgsLCQsL83czjAlYJ4FNwLc4PfZvgeLHV+vgBPyvgMHAEKBTFbXjrD16VS0AZgCfAVuBf6jqFhF5WkSKp0p+BmSKSCLwOfCoqmYCPYAEEdns3v6c52ydqrD94HGuf+krXohP5khOPi/EJzPm5a/YfvC4Tz9nypQp3H333QwaNIjf/OY3fPfddwwZMoTY2Fguvvhitm3bBsCqVasYPXo04HyTmDp1KsOGDaNLly68+OKLJe/XuHHjkuOHDRvG+PHj6d69O7fccgvFVcA++eQTunfvTv/+/XnggQdK3tdTeno6l156KXFxccTFxZX5BvKXv/yFPn36EBMTw2OPPQZASkoKV155JTExMcTFxZGamlqmzQAzZsxg0aJFgLNExW9/+1vi4uJ4//33ef311xkwYAAxMTHceOON5OTkALBv3z7GjRtHTEwMMTExrFmzhieeeILZs2eXvO8f/vAH5syZU+l/C2MCgQI7gPeAh3GC+wKcEH8IWIMzs2WW+89HgbU489YnAZ2Bqrrz5NUYvap+AnxSbtsTHn9W4BH3L89j1gB9Kt/MUv/98RYSdx897f71Px+moKh0mP9EfiFbdh9l5Kwv6N+peYXn9Gx3AU9e3+uc25KRkcGaNWsICwvj6NGjrF69mtq1a7N8+XJ+//vf869//euUc3766Sc+//xzsrOz6datG/fcc88pc8E3btzIli1baNeuHUOHDuXrr7/G5XIxffp0vvzySyIjI5k0aVKFbWrVqhXx8fHUr1+f5ORkJk2aREJCAp9++ikfffQRa9eupWHDhhw6dAiAW265hccee4xx48aRm5tLUVERO3furPC9i4WHh7NhwwbAGda66667AHj88cdZuHAh999/Pw888ACXX345H374IYWFhRw7dox27dpxww038NBDD1FUVMTixYv57rvvzvnv3ZhAcBxYj9NLL/61x72vAeACHsQJ+kGcOoOlOgXcomaV1aBuGNm5BRVu97WbbrqpZOgiKyuLO+64g+TkZESE/Pz8Cs+57rrrqFevHvXq1aNVq1bs27ePiIiIMscMHDiwZFu/fv1IT0+ncePGdOnSpWTe+KRJk5g/f/4p75+fn8+MGTPYtGkTYWFhJCUlAbB8+XLuvPNOGjZsCECLFi3Izs5m165djBs3DnAeQvLGzTffXPLnH3/8kccff5wjR45w7Ngxrr76agBWrlzJ22+/DUBYWBhNmzaladOmhIeHs3HjRvbt20dsbCzh4eFefaYx/qRACmWHYL4HCt37LwJGUDoE0wdnaCZQBF3Qn63n/eHGDB7/8EeO5xWWbGtUN4ynx/ZiXGzEGc48d40aNSr58x//+EeGDx/Ohx9+SHp6OsOGDavwnHr16pX8OSwsjIKCU78peXPM6bzwwgu0bt2azZs3U1RU5HV4e6pduzZFRUUlr8vPV/e87ilTprBkyRJiYmJYtGgRq1atOuN7/+pXv2LRokXs3buXqVOnnnPbjKkOWcB3lO2tH3Lva4IzBPM7SnvrLf3QxnMRcmvdjOjR+pQbr2G1hBE9Wlfp52ZlZdG+vfPDWfF4ti9169aNtLQ00tPTAXjvvfdO2462bdtSq1Yt3nnnHQoLnW94I0eO5M033ywZQz906BBNmjQhIiKCJUuWAHDy5ElycnLo1KkTiYmJnDx5kiNHjrBixYrTtis7O5u2bduSn5/Pu+++W7J9xIgRzJs3D3Bu2mZlZQEwbtw4/vOf/7Bu3bqS3r8x/lSIM71xAc6N0d5Ac+Aq4Emcm6fjgNdx1nI5DCwHngGuI/BDHoKwR382F9Svw/dPVX+A/OY3v+GOO+7gT3/6E9ddd53P379BgwbMnTuXUaNG0ahRIwYMGFDhcffeey833ngjb7/9dsmxAKNGjWLTpk24XC7q1q3Ltddey7PPPss777zD9OnTeeKJJ6hTpw7vv/8+Xbp0YcKECfTu3ZvIyEhiY08/I/aZZ55h0KBBXHjhhQwaNIjs7GwA5syZw7Rp01i4cCFhYWHMmzePIUOGULduXYYPH06zZs1sxo7xi4M4N0GLh2C+A7Ld+1rg9NJvxhmCGYAz/THYSfGMjkDhcrm0fOGRrVu30qNHDz+1KHAcO3aMxo0bo6rcd999REVF8fDDD/u7WeekqKioZMZOVFRUpd7Lvi7M2eTjjKV7DsGkuPeFAX1xAn2w+9dFVN3Ml6omIutVtcK53CHXow9lr7/+Om+99RZ5eXnExsYyfXpVPENXdRITExk9ejTjxo2rdMgbU5HdlA31BOCEe18bnFC/CyfU+wONKniPUGQ9ehO07OuiZssFNlI6BPMtpYty1QXiKJ0FMxjn8f5g7a17w3r0xpigpkA6ZXvrG3GGZsB5onQopUMw/YB6p7xLzWVBb4wJOMdwhl08g32fe19DnJukj1A6vbGtH9oYTCzojTF+VQQkU3YI5gf3dnAWzrqa0iGY3lhwnSv7+zLGVKvDlH0Yaa17GzhTGQfhVDYajPNgkj07XXkh98BUVRg+fDifffZZmW2zZ8/mnnvuOe05w4YNo/im8rXXXsuRI0dOOeapp57i+eefP+NnL1myhMTE0nXgnnjiCZYvX34uzTfGbwpxpjfOB6YCPXHmqo8C/htnOdzxwEJgC87Tp5+5912DhbyvWI/eC5MmTWLx4sVlnuRcvHgxf/2rdysuf/LJJ2c/6DSWLFnC6NGj6dmzJwBPP/30eb+Xv9hyxjXHfsqOq6/DGW8H5wnSwcAtOMMwLpzVHU3Vsx69F8aPH8+///3vkiIj6enp7N69m0svvZR77rkHl8tFr169ePLJJys8v3Pnzhw8eBCAP//5z0RHR3PJJZeULGUMVLjc75o1a1i6dCmPPvoo/fr1IzU1lSlTpvDPf/4TgBUrVhAbG0ufPn2YOnUqJ0+eLPm8J598kri4OPr06cNPP/10SptsOWNTWXk4Qf4STnh3BVrjDLv8Dedp0ynA/+A8pLQf+Bj4A3AFFvLVKeh69A/hLOTvS/2A2WfY36JFCwYOHMinn37K2LFjWbx4MRMmTEBE+POf/0yLFi0oLCxkxIgRfP/99/Tt27fC91m/fj2LFy9m06ZNFBQUEBcXR//+/QG44YYbKlzud8yYMYwePZrx48eXea/c3FymTJnCihUriI6O5vbbb2fevHk89NBDALRs2ZINGzYwd+5cnn/+eRYsWFDmfFvO2JyrDMr21tfjzGUHaIfTS78Hp9cehzM7xgSGoAt6fykevikO+oULFwLwj3/8g/nz51NQUMCePXtITEw8bdCvXr2acePGlSwVPGbMmJJ9p1vu93S2bdtGZGQk0dHRANxxxx288sorJUF/ww03ANC/f38++OCDU8635YzNmZzg1LXWi+uH1sN5qvQ+Suet+3ZdWONrQRf0Z+p5V6WxY8fy8MMPs2HDBnJycujfvz/bt2/n+eefZ926dTRv3pwpU6acsqSvt851ud+zKV7q+HTLHNtyxqaYAmmUDfVNOEWrAboAl1Ma6jE4T56a4GFj9F5q3Lgxw4cPZ+rUqSXVnY4ePUqjRo1o2rQp+/bt49NPPz3je1x22WUsWbKEEydOkJ2dzccff1yy73TL/TZp0qRkRUhP3bp1Iz09nZQUZ4mmd955h8svv9zr67HljGuubGAl8CxwPdAKZzGvW4E3cdZbfxT4CKeQdSrwLnA/zoNKFvLBx4L+HEyaNInNmzeXBH1MTAyxsbF0796dyZMnM3To0DOeHxcXx80330xMTAzXXHNNmaWGi5f7HTp0KN27dy/ZPnHiRP72t78RGxtLampqyfb69evz5ptvctNNN9GnTx9q1arF3Xff7fW13Hvvvbz11lvExMTw008/lVnOeMyYMbhcLvr161cy/fOdd97hxRdfpG/fvlx88cXs3buXDh06lCxnPGHCBK+WMy5/fXPmzOHzzz+nT58+9O/fv2QqafFyxhMmTLAZO5VQBCQCbwDTcFZrbIpTDekPODdJrwdeAzbjFNwo/iYwBufmqgl+tqiZCUjeLGdsXxenOoTzAJLnw0hZ7n3NKB1+KX4YqeIqyiYY2aJmJqjYcsbeKcCpjORZxzTJva8WTt3SiZQGezT2I3xNZUFvAk7Pnj1JS0vzdzMCzl5OfRgpx72vFc70xjtxQt0FNPZDG01gCpqgV1VEQnk1aXMuAm3I0ddO4sx88Qz2dPe+OkAsTn3T4t56Z0J7rXVTOUER9PXr1yczM5Pw8HALe4OqkpmZeV5TQgOR4hTM8ByC2YDz5Ck4BTMG48x6GYIT8qFx5aa6BEXQR0REkJGRwYEDB/zdFBMg6tevT0REcD6mc5xTH0ba497XAGfY5UFK11pv74c2mtASFEFfp04dIiMj/d0MY86Z4kxh9Az1zTirOoIzf30EpUMwfXGGZozxpaAIemOCRRbOTdLiIZi1QKZ7XxOcKY2P4QzBDAQu9EMbTc1jQW/MeSoEtlK2t56I04sHZ+31X1DaW+8B2KNfxh+8CnoRGQXMwfk6XaCqz1VwzATgKZyv882qOtm9/Q7gcfdhf1LVt3zQbmOq3UFOfRipeHGKFjhhfrP79wE4DygZEwjOGvQiEga8AozEWal0nYgsVdVEj2OigN8BQ1X1sIi0cm9vATyJc39JgfXucw+X/xxjAkk+TmUkz956intfGM5Y+q2U1jG9CJveaAKXNz36gUCKqqYBiMhinNoCiR7H3AW8Uhzgqrrfvf1qIF5VD7nPjcepIvZ33zTfGN/YTdlQT8BZqhegDU6g34UT6v2BRhW8hzGBypugb48zzbdYBs6sL0/RACLyNU6H5ylV/c9pzrXZYsavcoGNlIb6N5R+kdbFKZoxndKx9Y5Yb90EN1/djK0NRAHDcGoQfCkifbw9WUSm4SyuR8eOHX3UJGOc8cJ0yvbWN+IMzQB0Ai6mdAimH05hDWNCiTdBvwvn4bxiEZQWmymWAaxV1Xxgu4gk4QT/Lpzw9zx3VfkPUNX5OIXicblcof1su6lSx3CGXTyDfZ97X0Ocm6SPUPowUls/tNGY6uZN0K8DokQkEie4JwKTyx2zBJgEvCkiLXGGctJwahY8KyLFq6FehXPT1phKKwKSKbt0wA/u7eB8EV5N6RBMH2w+sQlMhUXKwq/SmLsqlXuHdeWXl3QhrJbvBgzP+nWvqgUiMgP4DGf8/Q1V3SIiTwMJqrrUve8qEUnEmV78qKpmAojIMzjfLACeLr4xa8y5Ogx8R9npjcXTty7A6aE/Tula61Zl1gSD7QePc9+7G9h+8Dgn8gt5IT6Zjzbt5uXJcUS29M1t/6AoPGJqnkJgC2WHYLa69wnQm7JFNLpja62b4NT/mXgO5+RR5BHFtQSaN6zL+j+O9Pp9rPCICXj7cXroxUMw63DG2wFa4oT5LZQ+jHSBH9pojK/lFxbRtEEdMo/nldlepBDduonPPseC3lS7PJyFvTx768VlRmoDMcAUSnvrXbDpjSa0FBYpH23axezlyew4lEMtoUyPvlHdMCYM8N3qrBb0psplUDbU1+PMZQdohzO18R6cUI/DmR1jTCgqKlI+/XEvLyxPImX/MXq2vYCXJ/fj9x/8yNHcgpLjwmoJI3r4rjS7Bb3xqRM4RTOKh2C+pXQubj2cp0rvxQn1ITjzbY0JdarKiq37mRmfxNY9R4lq1Zh5t8Rxda821KoljO5btc+RWtCb86Y4Qy6evfVNOEWrASKByykdgonBefLUmJpCVVmdfJCZ8Uls3nmEzuENmX1zP66PaefT6ZNnY0FvvJaNc5PUM9iLa341wpnS+CilDyP57gdPY4LP2rRMZi5L4rv0Q7Rv1oC/3tiXG+LaUzus+ueHWdCbChUB2yg7BPMjpWutdweuo7S33gv7YjIGYOOOw8yKT2J18kFaNanHM2N7MWFAB+rV9l81Avu/aQA4xKlrrWe59zXDCfMbKX0YqXkF72FMTbZldxYvxCexfOt+WjSqy+PX9eDWwZ2oX8f/5WYs6GugApzeuecQzDb3vlo4SwVMpLS3Ho09jGTM6STvy+aF5Ul88sNeLqhfm0ev7saUizvTqF7gxGvgtMRUmb2UDfV1QI57XyucML+D0oeRGvuhjcYEm/SDx5mzIpklm3bRsE4YD4yI4peXRNK0QeCVd7egDzEncWa+eAZ7untfHSAW+BWlvfXO2MNIxpyLXUdO8NKKZN5fn0GdMGHaZV2YfllXWjQK3DllFvRBTHEKZniG+gacsAdnbenBwP3u32OBBtXfTGNCwv6jubzyeQp//84pU3Pb4E7cO7wrrZrU93PLzs6CPojkcOpa63vc++rjFOa9H+dBpEFYKS9jfCHz2Ele/SKVt7/5mcIi5SZXB+6/4iLaNQuebpMFfYBSnGLUnqG+GWdVR3CKUY+gdAimL87QjDHGN7Jy8nl9dRpvfL2d3PxCxsVG8OCIKDqGB98iHRb0ASKLUx9GynTva4IzpfExSh9GutAPbTSmJjh2soA3v9rO/NVpZOcWMLpvWx66MpqLWgXvNAULej8oAhIpG+qJlD6M1BMYS2kd0x44FV+MMVXnRF4h73ybzrxVqRzOyWdkz9Y8MjKaHm2Df1FsC/pqcJCyDyN9Bxx172uBE+Y3Uzq9sZkf2mhMTXWyoJC/r93BK6tSOZB9ksujL+SRkdHEdAid/4kW9D6Wj1O31LOOaYp7XxjOWHpxAY3BOBXUbXqjMdUvv7CIf67P4KUVyezOymVQZAvm3hLHgM4t/N00n7Ogr6TdlB2CScBZqhecRb2GAHfhhHp/nMW/jDH+U77oR2zHZvztphgu7hqOSGh2uyzoz0EusJGywb7Dva8uTtGM6ZT21jtivXVjAkVRkfLJj3t4IT6J1APH6dXuAt6Y4mJ4t1YhG/DFLOhPQ4GfKTsEsxFnaAagE05v/WFKH0aqV/3NNMachaqyfOt+Zi7bxk97s4lq1ZhXb43jqp5O0Y+awILe7RinPoy0z72vAc5N0kcond7Y1g9tNMZ4r6Tox7JtbM7IonN4Q+ZM7MfovtVb9CMQ1MigLwKSKRvq37u3g7Na49WUDsH0oYb+RRkTpAKp6EcgqBH5dQRnSmPxEMxa4LB73wU4PfQ/UNpbD/dDG40xlbdhx2FmLUviq5TAKfoRCEIu6AuBLZTtrW917xOcSkjjKe2td8fWWjcm2P24yyn6seKn/YQHWNGPQBAyQb8buA2n537Mva0lTpgXz1sfgNODN8aEhmAo+hEIQuZvoyXO6o7FBTQGA12x6Y3GhCLPoh+N6tYO6KIfgSBkgr4uzhi8MSZ0ZRzO4aUVKfxzQ/AU/QgEIRP0xpjQta+k6McOBOH2IZ24Z1hwFP0IBF4FvYiMAubgLNeyQFWfK7d/CvA3YJd708uqusC9rxBn+ReAHao6xgftNsbUAAePneTVVam8861T9GPCgA7MGB5cRT8CwVmDXkTCgFeAkUAGsE5ElqpqYrlD31PVGRW8xQlV7Vf5phpjaoqsnHzmr07lza/Tg77oRyDwpkc/EEhR1TQAEVmMs1x6+aA3xphKyc7N582v03ndXfTj+ph2PHRlFF0vDN6iH4HAm6Bvj1ODulgGznNF5d0oIpcBScDDqlp8Tn0RSQAKgOdUdUn5E0VkGjANoGPHjufQfGNMKDiRV8jb36Tz6hdO0Y+rerbm4RAp+hEIfHUz9mPg76p6UkSmA28BV7j3dVLVXSLSBVgpIj+oaqrnyao6H5gP4HK5FGNMjZCbX8jfv9vBK5+ncvDYSYZ1c4p+9I0InaIfgcCboN8FdPB4HUHpTVcAVDXT4+UC4K8e+3a5f08TkVU4Cz2WCXpjTM2SX1jE+wkZvLQymT1ZuQzu0oJXb43DFYJFPwKBN0G/DogSkUicgJ8ITPY8QETaquoe98sxuFcdEJHmQI67p98SGIrHNwFjTM1SWKQs2biLOSucoh9xHZsx86YYLr6opb+bFtLOGvSqWiAiM4DPcKZXvqGqW0TkaSBBVZcCD4jIGJxx+EPAFPfpPYDXRKQIZ0mZ5yqYrWOMCXFFRcq/f9jD7OWlRT/enDKAYd0uDPmiH4FAVANrSNzlcmlCQoK/m2GM8QFVJT5xH7Pik/hpbzbRrRvzyMhuXN2rtQW8j4nIelV1VbTPnow1xvicqvKlu+jH9xlZRLZsVGOLfgQCC3pjjE99m5bJzGXbWJd+2Cn6Mb4vN8TW3KIfgcCC3hjjExt2HGbmsm18nZJJ6wvq8cwvenOzqwN1a1vA+5sFvTGmUn7clcWs+CRWuot+/HF0T24Z1NGKfgQQC3pjzHlJ2pfNC/FJfPrjXpo2qMNvRnXjjiFW9CMQ2b+IMeacbD94nDnLk/ho824a1a3NgyOi+OWlkVxQ34p+BCoLemOMV3YeyuGllcn8a8Mu6obVYvplXZl+WReaW9GPgGdBb4w5o31Hc3l5ZQqL1+1ARLhjSGfuGdaVC5vU83fTjJcs6I0xFSpf9OPmAR2YccVFtG1qRT+CjQW9MaaMIzl5vL46raToxw1xTtGPDi2s6EewsqA3xgBO0Y83vkpnweo0juUVcH3fdjxoRT9CggW9MTVcTl4Bb3/zM69+kcqRnHyu7uUU/ejexop+hAoLemNqKCv6UXNY0BtTw+QVFPH++p28vDKFPVm5DOkSbkU/QpwFvTE1REFhEUs27WbOiiR2HjphRT9qEAt6Y0JccdGPF5YnkXbgOL3bX8DTd/ZmWLQV/agpLOiNCVEVFf149db+VvSjBrKgNybEqCpfJB1gVnySFf0wgAW9MSHlm1Sn6EfCz4eJaN6Av43vyzgr+lHjWdAbEwLW/3yYWfGlRT/+9IveTLCiH8bNgt6YIOZZ9KNlYyv6YSpmQW9MENq21yn68Z8tVvTDnJ19VRgTRLYfPM7s5UksdRf9eOjKKKZeYkU/zJlZ0BsTBMoX/bj78q5Mu9SKfhjvWNAbE8D2ZuXy8ufJvLdupxX9MOfNgt6YAHTw2EnmuYt+qDpFP+4bbkU/zPmxoDcmgBzJyWP+l07Rj5MFhdwYF8EDVvTDVJIFvTEBIDs3n4VfbWfh6u0cyytgTEw7HhwRRRcr+mF8wILeGD/KySvgrTU/89qXTtGPUb3a8PDIaLq1aeLvppkQ4lXQi8goYA4QBixQ1efK7Z8C/A3Y5d70sqoucO+7A3jcvf1PqvqWD9ptTFDLzS/kf9fuYO6qFA4ey2N4twt5ZGQ3+kQ09XfTTAg6a9CLSBjwCjASyADWichSVU0sd+h7qjqj3LktgCcBF6DAeve5h33SemOCTF5BEf9IcIp+7D2ay8Vdw3nttmj6d7KiH6bqeNOjHwikqGoagIgsBsYC5YO+IlcD8ap6yH1uPDAK+Pv5NdeY4FRQWMSHG3cxZ0UyGYdP0L9Tc2bdHMPFXa3oh6l63gR9e2Cnx+sMYFAFx90oIpcBScDDqrrzNOe2L3+iiEwDpgF07NjRu5YbEwSKipT/+2EPs+OTSDt4nD7tm/KnX/Tmciv6YaqRr27Gfgz8XVVPish04C3gCm9PVtX5wHwAl8ulPmqTMX6jqixL3MesZUls25dNt9ZNeO22/lzV04p+mOrnTdDvAjp4vI6g9KYrAKqa6fFyAfBXj3OHlTt31bk20phgoaqsSjrArGVJ/LAriy4tG/HipFhG92lLLSv6YfzEm6BfB0SJSCROcE8EJnseICJtVXWP++UYYKv7z58Bz4pIc/frq4DfVbrVxgSgNakHmbksifXuoh/P3xTDL/q1s6Ifxu/OGvSqWiAiM3BCOwx4Q1W3iMjTQIKqLgUeEJExQAFwCJjiPveQiDyD880C4OniG7PGhIr1Px9i5rIk1qRm0uaC+vx5XG9u6m9FP0zgENXAGhJ3uVyakJDg72YYc1Y/ZGQxK34bn287QMvGdbl32EVMtqIfxk9EZL2quiraZ0/GGnOOtu3NZlb8Nj7bso9mDevw21HduePiTjSsa/+dTGCyr0xjvJR24Bizl3iPasEAAA63SURBVCfz8fe7aVy3Ng9fGc3USzrTxIp+mABnQW/MWew8lMOLK5L514YM6tUO457LuzLtsi40a2hFP0xwsKA35jTKF/24c2gk9wzrSsvGVvTDBBcLemPKOZDtFP34n7VO0Y+JAzpy3/CLaNO0vr+bZsx5saA3xu1ITh6vfZnGoq/TySss4sa49tx/hRX9MMHPgt7UeEdz83nDin6YEGZBb2qsnLwCFq1JZ/6XaVb0w4Q0C3pT4+TmF/Lu2h3Mcxf9uKJ7Kx4ZGU3v9lb0w4QmC3pTY5Qv+jH0onBeG9mN/p2an/1kY4KYBb0JeeWLfris6IepYSzoTcgqKlI+/n43c5YnW9EPU6NZ0JuQo6p8tmUfL8Q7RT+6t2nC/Nv6M9KKfpgayoLehIxTin5c2IiXJsVynRX9MDWcBb0JCZ5FPzq0sKIfxniyoDdBbf3Ph3j+syS+ScukbVMr+mFMRSzoTVD6ISOLmfHbWLXtAC0b1+PJ63syaaAV/TCmIhb0Jqj8tPcoL8QnlRT9eOya7tw+xIp+GHMm9r/DBIVUd9GP/7OiH8acMwt6E9B2HsphzopkPtiQQf06Ydw7rCt3XWpFP4w5Fxb0JiDtyTrByytTeG/dTsJqCVOHRnK3Ff0w5rxY0JuAciD7JHNXpfDu2h2oKpMHOUU/Wl9gRT+MOV8W9CYgHD7uFP14a41T9GN8XAT3j7iIiOZW9MOYyrKgN351NDefhau3s/Cr7RzPK2BsTDsevDKayJaN/N00Y0KGBb3xi+MnS4t+ZJ3I55reTtGP6NZW9MMYX7OgN9UqN7+Q//n2Z+atSiXzeB4jurfiYSv6YUyVsqA31SKvoIj3Enby8spk9h09ySUXteSRq6KJ62hFP4ypahb0pkoVFBbxwcZdzFmezK4jJxjQuTmzb45lSNdwfzfNmBrDq6AXkVHAHCAMWKCqz53muBuBfwIDVDVBRDoDW4Ft7kO+VdW7K9toE/gKi5T/+343s5cns/3gcfpGNOXZG/pwWVRLWxPemGp21qAXkTDgFWAkkAGsE5GlqppY7rgmwIPA2nJvkaqq/XzUXhPgnKIfe5kVn0TSvmN0b9OE1293cWWPVhbwxviJNz36gUCKqqYBiMhiYCyQWO64Z4C/AI/6tIUmKKgqq7YdYGb8Nn7cdZQuFzbi5cmxXNvbin4Y42/eBH17YKfH6wxgkOcBIhIHdFDVf4tI+aCPFJGNwFHgcVVdXZkGm8CzJuUgzy/bxoYdR+jQogEzb4phrBX9MCZgVPpmrIjUAmYBUyrYvQfoqKqZItIfWCIivVT1aLn3mAZMA+jYsWNlm2SqSUL6IZ5fto1v0w7Rtml9nh3Xh5tcEdSxgDcmoHgT9LuADh6vI9zbijUBegOr3GOwbYClIjJGVROAkwCqul5EUoFoIMHzA1R1PjAfwOVy6fldiqku32ccYeayJL5Icop+PHV9TyZa0Q9jApY3Qb8OiBKRSJyAnwhMLt6pqllAy+LXIrIK+LV71s2FwCFVLRSRLkAUkObD9ptq9NPeo8xalsSyxH00b1iH313TnduHdKZBXQt4YwLZWYNeVQtEZAbwGc70yjdUdYuIPA0kqOrSM5x+GfC0iOQDRcDdqnrIFw031ad80Y9HRkZz51Ar+mFMsBDVwBopcblcmpCQcPYDTZXbkekU/fhwo1P0Y+rQSO66tAtNG1rAGxNoRGS9qroq2mdPxppT7Mk6wUsrU/iHu+jHLy+J5O7LuxJuRT+MCUoW9KbE/uxc5q1KtaIfxoQYC3rD4eN5vPplKm+v+dmKfhgTgizoa7CjufksWL2dN9xFP37Rrz0PjoiisxX9MCakWNDXQOWLflzbpw0PXWlFP4wJVRb0NYgV/TCmZrKgrwHyCop4b90OXv48xYp+GFMDWdCHsILCIj7YsIs5K0qLfsyZGMvgLlb0w5iaxII+BJUv+hET0ZT/d0MfLrWiH8bUSBb0IcSKfhhjKmJBHwJUlc+37WfmsiS27D5KVyv6YYzxYEEfxFSVNamZPL9sGxt3HKFji4bMmhDD2H7tCbOAN8a4WdAHqXXph5jpUfTj/93Qh/H9reiHMeZUFvRBZvPOI8yMT+JLK/phjPGSBX2Q2LrnKLPik4h3F/34/bXduW2wFf0wxpydBX2AS9l/jNnLk/i/7/fQpH5t/mtkNHdeEknjevZPZ4zxjqVFgNqRmcPsFUks2biLBnXCuP+Ki/jVJVb0wxhz7izoA8zuI07Rj/cTnKIfv7q0C9Mv62JFP4wx582CPkDsz85l7uep/O/aHSjKLe6iH62s6IcxppIs6P3s0PE8Xvsilbe+SSe/ULmpfwQzrrCiH8YY37Gg95OsE/ksXJ3Gwq+2k5NfyLh+7XnAin4YY6qABX01Ky768doXqRzNLeC6Pm156MoooqzohzGmiljQV5Pioh9zV6Vy6HgeV/Zwin70amdFP4wxVcuCvoqdLCjkvXU7eXllCvuzT3JpVEseGRlNrBX9MMZUEwv6KpJfWMQHGzJ4cUUKu46cYGDnFrw0KZZBVvTDGFPNLOh9rLBI+XjzbmYvTyI9M4eYDs147sY+XHKRFf0wxviHBb2PFBWVFv1I3n+MHm0vYMHtLkZY0Q9jjJ9Z0FeSqrLyJ6foR+Keo1zUqjGvTI7jmt5trOiHMSYgWNCfJ1Xl6xSn6MemnUfoFN6QF26OYUyMFf0wxgQWr6pUiMgoEdkmIiki8tgZjrtRRFREXB7bfuc+b5uIXO2LRvvbd9sPMXH+t9y6cC37j+by3A19WP7I5YyLjbCQN8YEnLP26EUkDHgFGAlkAOtEZKmqJpY7rgnwILDWY1tPYCLQC2gHLBeRaFUt9N0lVB/Poh8XNqnHf4/pxcSBHahX29aEN8YELm+GbgYCKaqaBiAii4GxQGK5454B/gI86rFtLLBYVU8C20Ukxf1+31S24dUpcbdT9GP51n20aFSXP1zbg1sHd7KiH8aYoOBN0LcHdnq8zgAGeR4gInFAB1X9t4g8Wu7cb8ud2778B4jINGAaQMeOHb1reTVI2Z/NC8uT+be76Mevr4pmylAr+mGMCS6VTiwRqQXMAqac73uo6nxgPoDL5dLKtqmyfs48zpwVyVb0wxgTErwJ+l1AB4/XEe5txZoAvYFV7vnibYClIjLGi3MDyq4jJ3h5ZTLvJ2RY0Q9jTMjwJujXAVEiEokT0hOBycU7VTULaFn8WkRWAb9W1QQROQH8r4jMwrkZGwV857vm+8b+o7nMXeUU/QC4dXAn7h3W1Yp+GGNCwlmDXlULRGQG8BkQBryhqltE5GkgQVWXnuHcLSLyD5wbtwXAfYE046Z80Y8JrghmXBFF+2YN/N00Y4zxGVH1+5B4GS6XSxMSEqr0M6zohzEm1IjIelV1VbSvRk0fOXaygEVfb2f+l2lW9MMYU2PUiKDPzS/knW9+Zt4XxUU/WvPwyCgr+mGMqRFCOugrKvrxX1d1o1+HZv5umjHGVJuQCfrCImXhV2nMXZXK3Zc5c95fXplqRT+MMTVeSAT99oPHue/dDWw/eJwT+YX85T/bUKB7mya888uBVvTDGFOjhUTQj5+3hsM5eRS5JxApIAIHsk9yadSFfm2bMcb4m1fLFAe6qNaNS0K+mCpE22waY4wJjaC/eUAHGpVbSbJR3TAmDIjwU4uMMSZwhETQj+jR+pSCH2G1hBE9WvupRcYYEzhCYoz+gvp1+P6pkCheZYwxPhcSPXpjjDGnZ0FvjDEhzoLeGGNCnAW9McaEOAt6Y4wJcRb0xhgT4gKu8IiIHAB+rsRbtAQO+qg5waKmXXNNu16wa64pKnPNnVS1wjVfAi7oK0tEEk5XZSVU1bRrrmnXC3bNNUVVXbMN3RhjTIizoDfGmBAXikE/398N8IOads017XrBrrmmqJJrDrkxemOMMWWFYo/eGGOMBwt6Y4wJcUEZ9CLyhojsF5EfT7NfRORFEUkRke9FJK662+hrXlzzLe5r/UFE1ohITHW30dfOds0exw0QkQIRGV9dbasK3lyviAwTkU0iskVEvqjO9lUFL76um4rIxyKy2X3Nd1Z3G31NRDqIyOcikui+pgcrOManGRaUQQ8sAkadYf81QJT71zRgXjW0qaot4szXvB24XFX7AM8QGjeyFnHma0ZEwoC/AMuqo0FVbBFnuF4RaQbMBcaoai/gpmpqV1VaxJn/je8DElU1BhgGzBSRutXQrqpUAPyXqvYEBgP3iUjPcsf4NMOCMuhV9Uvg0BkOGQu8rY5vgWYi0rZ6Wlc1znbNqrpGVQ+7X34LBH0dRS/+nQHuB/4F7K/6FlUtL653MvCBqu5wH18TrlmBJiIiQGP3sQXV0baqoqp7VHWD+8/ZwFagfbnDfJphQRn0XmgP7PR4ncGpf5Gh7JfAp/5uRFUTkfbAOELjJzZvRAPNRWSViKwXkdv93aBq8DLQA9gN/AA8qKpF/m2S74hIZyAWWFtul08zLCRKCZpSIjIcJ+gv8XdbqsFs4LeqWuR0+EJebaA/MAJoAHwjIt+qapJ/m1WlrgY2AVcAXYF4EVmtqkf926zKE5HGOD+NPlTV1xOqQb8L6ODxOsK9LaSJSF9gAXCNqmb6uz3VwAUsdod8S+BaESlQ1SX+bVaVyQAyVfU4cFxEvgRigFAO+juB59R54CdFRLYD3YHv/NusyhGROjgh/66qflDBIT7NsFAdulkK3O6+cz0YyFLVPf5uVFUSkY7AB8BtId7DK6GqkaraWVU7A/8E7g3hkAf4CLhERGqLSENgEM74bijbgfMTDCLSGugGpPm1RZXkvt+wENiqqrNOc5hPMywoe/Qi8necO/AtRSQDeBKoA6CqrwKfANcCKUAOTq8gqHlxzU8A4cBcdw+3INhX/vPimkPK2a5XVbeKyH+A74EiYIGqnnHqaaDz4t/4GWCRiPwACM5QXbAvXTwUuA34QUQ2ubf9HugIVZNhtgSCMcaEuFAdujHGGONmQW+MMSHOgt4YY0KcBb0xxoQ4C3pjjAlxFvTGGBPiLOiNMSbE/X/jIf1XneyxBwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: [0.5583258867263794, 0.6469278931617737]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "xdJH3Muot7ku",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Data Question\n",
        "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
        "\n",
        "**ANSWER**: The pad_sequences method ensures that all the lists are the same length. Needed to enter it into the model so that it can process each observation equivalently. The shapes wouldn't fit properly otherwise\n",
        "\n",
        "\n",
        "## RNNs versus LSTMs\n",
        "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
        "**ANSWER**: LSTMs are able to be customized to have remember and forget parameters, specifying dropout in between recursions and also between the LSTM and the Dense layer. This allows for weighting of recent information vs. long term. \n",
        "\n",
        "\n",
        "## RNN / LSTM Use Cases\n",
        "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
        "**ANSWER**: Vanilla neural Networks aren't great at capturing features from sequence data, that's where RNN and LSTM shine. So these recursive neural networks work well with text data because the order of the characters and words are the main source of meaning. Time series data matters because the chronology is of interest. These models are also suited well for audio data because the melody is just sequence of frequencies. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread_collection\n",
        "from skimage.transform import resize #This might be a helpful function for you\n",
        "\n",
        "images = imread_collection('./frog_images/*.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "03327e5d-4ca7-445f-d31a-fdbe79aab956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(type(images))\n",
        "print(type(images[0]), end=\"\\n\\n\")\n",
        "\n",
        "print(\"Each of the Images is a Different Size\")\n",
        "print(images[0].shape)\n",
        "print(images[1].shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'skimage.io.collection.ImageCollection'>\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "Each of the Images is a Different Size\n",
            "(2137, 1710, 3)\n",
            "(3810, 2856, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO1DT03l46at",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "edbd9002-1fc8-43b8-88dd-c2dd0150eb20"
      },
      "source": [
        "# reshape the image\n",
        "image_reshape = []\n",
        "for image in images:\n",
        "  image_reshape = resize(image, output_shape=(224,224,3))\n",
        "\n",
        "print(image_reshape[0].shape)\n",
        "print(image_reshape[1].shape)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 3)\n",
            "(224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model. Print out the predictions in any way you see fit. \n",
        "\n",
        "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goal* - Check for other things such as fish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cO63SKkEz-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "def process_img_path(img_path):\n",
        "  return image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "def img_contains_frog(img):\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  model = ResNet50(weights='imagenet')\n",
        "  features = model.predict(x)\n",
        "  results = decode_predictions(features, top=3)[0]\n",
        "  print(results)\n",
        "  for entry in results:\n",
        "    if entry[1] == 'bullfrog':\n",
        "      return entry[2]\n",
        "    if entry[1] == 'tree frog':\n",
        "      return entry[2]\n",
        "    if entry[1] == 'tailed frog':\n",
        "      return entry[2]\n",
        "  return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_QT8EWMJcee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "c81f784e-a76d-499d-82ad-772a3af4a80f"
      },
      "source": [
        "# Let's compare full image with resized\n",
        "# Full image\n",
        "for img in images:\n",
        "  img_contains_frog(img)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_5:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2137, 1710, 3).\n",
            "[('n01930112', 'nematode', 0.032350022), ('n01496331', 'electric_ray', 0.015001914), ('n03445777', 'golf_ball', 0.014543021)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_6:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3810, 2856, 3).\n",
            "[('n09472597', 'volcano', 0.12513255), ('n01930112', 'nematode', 0.08108736), ('n03773504', 'missile', 0.048901953)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_7:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3456, 4608, 3).\n",
            "[('n01930112', 'nematode', 0.15511686), ('n04525038', 'velvet', 0.07890502), ('n02219486', 'ant', 0.029604794)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_8:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2500, 3335, 3).\n",
            "[('n02219486', 'ant', 0.12076042), ('n02233338', 'cockroach', 0.040772017), ('n02259212', 'leafhopper', 0.038669467)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_9:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2000, 3008, 3).\n",
            "[('n03196217', 'digital_clock', 0.10913357), ('n01833805', 'hummingbird', 0.06624019), ('n01873310', 'platypus', 0.042204827)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_10:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2883, 4319, 3).\n",
            "[('n02165456', 'ladybug', 0.11579637), ('n02219486', 'ant', 0.07187931), ('n03804744', 'nail', 0.070807554)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 4000, 6000, 3).\n",
            "[('n04409515', 'tennis_ball', 0.41539028), ('n04525038', 'velvet', 0.1514141), ('n03445777', 'golf_ball', 0.098719925)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_12:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2642, 3918, 3).\n",
            "[('n01944390', 'snail', 0.03210694), ('n01739381', 'vine_snake', 0.031411584), ('n02165456', 'ladybug', 0.030013904)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_13:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3456, 5184, 3).\n",
            "[('n01930112', 'nematode', 0.5404693), ('n04592741', 'wing', 0.08630957), ('n02165456', 'ladybug', 0.059288472)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_14:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2912, 4368, 3).\n",
            "[('n02165456', 'ladybug', 0.050584592), ('n01930112', 'nematode', 0.048977006), ('n02219486', 'ant', 0.036701765)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_15:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 4928, 3285, 3).\n",
            "[('n01930112', 'nematode', 0.11537263), ('n04409515', 'tennis_ball', 0.07722937), ('n03445777', 'golf_ball', 0.027443977)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_16:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3702, 5397, 3).\n",
            "[('n01930112', 'nematode', 0.48411828), ('n04409515', 'tennis_ball', 0.028047556), ('n03196217', 'digital_clock', 0.024263522)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_17:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 1856, 2784, 3).\n",
            "[('n01737021', 'water_snake', 0.11810874), ('n01644900', 'tailed_frog', 0.09170242), ('n01641577', 'bullfrog', 0.0640799)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_18:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2592, 3872, 3).\n",
            "[('n02268853', 'damselfly', 0.15339303), ('n01930112', 'nematode', 0.095723234), ('n02264363', 'lacewing', 0.0907457)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_19:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2673, 3382, 3).\n",
            "[('n03196217', 'digital_clock', 0.59746796), ('n01930112', 'nematode', 0.38583672), ('n04409515', 'tennis_ball', 0.0032123786)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVKN0i5VKDX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "aee8db66-0f14-4ecf-fb9f-c117aa7c366b"
      },
      "source": [
        "# Resized\n",
        "for img in images:\n",
        "  img_contains_frog(resize(img, output_shape=(224,224,3)))\n",
        "\n",
        "# Resized is way worse"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('n06359193', 'web_site', 0.062323052), ('n03196217', 'digital_clock', 0.053685647), ('n01930112', 'nematode', 0.052812316)]\n",
            "[('n03729826', 'matchstick', 0.05975482), ('n06359193', 'web_site', 0.055888124), ('n03196217', 'digital_clock', 0.04703378)]\n",
            "[('n06359193', 'web_site', 0.05612775), ('n03729826', 'matchstick', 0.051401444), ('n03196217', 'digital_clock', 0.04932685)]\n",
            "[('n06359193', 'web_site', 0.0629571), ('n01930112', 'nematode', 0.052607417), ('n03196217', 'digital_clock', 0.04884168)]\n",
            "[('n06359193', 'web_site', 0.064803764), ('n01930112', 'nematode', 0.049625944), ('n03196217', 'digital_clock', 0.04514117)]\n",
            "[('n06359193', 'web_site', 0.062429693), ('n03196217', 'digital_clock', 0.04622219), ('n01930112', 'nematode', 0.04373119)]\n",
            "[('n06359193', 'web_site', 0.055801384), ('n03196217', 'digital_clock', 0.055428814), ('n03729826', 'matchstick', 0.052860036)]\n",
            "[('n03729826', 'matchstick', 0.051139507), ('n06359193', 'web_site', 0.048581924), ('n03196217', 'digital_clock', 0.04785697)]\n",
            "[('n06359193', 'web_site', 0.07434831), ('n01930112', 'nematode', 0.053617664), ('n03196217', 'digital_clock', 0.046670016)]\n",
            "[('n06359193', 'web_site', 0.06386194), ('n01930112', 'nematode', 0.048488133), ('n03196217', 'digital_clock', 0.04335035)]\n",
            "[('n06359193', 'web_site', 0.064859666), ('n01930112', 'nematode', 0.04875387), ('n03196217', 'digital_clock', 0.044015907)]\n",
            "[('n06359193', 'web_site', 0.05928078), ('n03729826', 'matchstick', 0.0507644), ('n01930112', 'nematode', 0.050515898)]\n",
            "[('n03729826', 'matchstick', 0.052103963), ('n04404412', 'television', 0.03866141), ('n03196217', 'digital_clock', 0.038168617)]\n",
            "[('n06359193', 'web_site', 0.062437583), ('n03196217', 'digital_clock', 0.054235563), ('n01930112', 'nematode', 0.04584513)]\n",
            "[('n06359193', 'web_site', 0.06611373), ('n01930112', 'nematode', 0.05281505), ('n03196217', 'digital_clock', 0.046687305)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUMRacg7LVYa",
        "colab_type": "code",
        "outputId": "87bca8aa-7154-48a1-ef85-e2450ed64001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Stretch, gone fishin'\n",
        "# Should be an easy switch for fish.\n",
        "\n",
        "def img_contains_fish(img):\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  model = ResNet50(weights='imagenet')\n",
        "  features = model.predict(x)\n",
        "  results = decode_predictions(features, top=3)[0]\n",
        "  print(results)\n",
        "  for entry in results:\n",
        "    if 'fish' in entry[1]:\n",
        "      return entry[2]\n",
        "  return 0.0\n",
        "\n",
        "for img in images:\n",
        "  img_contains_fish(img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_35:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2137, 1710, 3).\n",
            "[('n01930112', 'nematode', 0.032350022), ('n01496331', 'electric_ray', 0.015001914), ('n03445777', 'golf_ball', 0.014543021)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_36:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3810, 2856, 3).\n",
            "[('n09472597', 'volcano', 0.12513255), ('n01930112', 'nematode', 0.08108736), ('n03773504', 'missile', 0.048901953)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_37:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3456, 4608, 3).\n",
            "[('n01930112', 'nematode', 0.15511686), ('n04525038', 'velvet', 0.07890502), ('n02219486', 'ant', 0.029604794)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_38:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2500, 3335, 3).\n",
            "[('n02219486', 'ant', 0.12076042), ('n02233338', 'cockroach', 0.040772017), ('n02259212', 'leafhopper', 0.038669467)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_39:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2000, 3008, 3).\n",
            "[('n03196217', 'digital_clock', 0.10913357), ('n01833805', 'hummingbird', 0.06624019), ('n01873310', 'platypus', 0.042204827)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_40:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2883, 4319, 3).\n",
            "[('n02165456', 'ladybug', 0.11579637), ('n02219486', 'ant', 0.07187931), ('n03804744', 'nail', 0.070807554)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_41:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 4000, 6000, 3).\n",
            "[('n04409515', 'tennis_ball', 0.41539028), ('n04525038', 'velvet', 0.1514141), ('n03445777', 'golf_ball', 0.098719925)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_42:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2642, 3918, 3).\n",
            "[('n01944390', 'snail', 0.03210694), ('n01739381', 'vine_snake', 0.031411584), ('n02165456', 'ladybug', 0.030013904)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_43:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3456, 5184, 3).\n",
            "[('n01930112', 'nematode', 0.5404693), ('n04592741', 'wing', 0.08630957), ('n02165456', 'ladybug', 0.059288472)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_44:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2912, 4368, 3).\n",
            "[('n02165456', 'ladybug', 0.050584592), ('n01930112', 'nematode', 0.048977006), ('n02219486', 'ant', 0.036701765)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_45:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 4928, 3285, 3).\n",
            "[('n01930112', 'nematode', 0.11537263), ('n04409515', 'tennis_ball', 0.07722937), ('n03445777', 'golf_ball', 0.027443977)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_46:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3702, 5397, 3).\n",
            "[('n01930112', 'nematode', 0.48411828), ('n04409515', 'tennis_ball', 0.028047556), ('n03196217', 'digital_clock', 0.024263522)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_47:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 1856, 2784, 3).\n",
            "[('n01737021', 'water_snake', 0.11810874), ('n01644900', 'tailed_frog', 0.09170242), ('n01641577', 'bullfrog', 0.0640799)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_48:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2592, 3872, 3).\n",
            "[('n02268853', 'damselfly', 0.15339303), ('n01930112', 'nematode', 0.095723234), ('n02264363', 'lacewing', 0.0907457)]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_49:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 2673, 3382, 3).\n",
            "[('n03196217', 'digital_clock', 0.59746796), ('n01930112', 'nematode', 0.38583672), ('n04409515', 'tennis_ball', 0.0032123786)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "__*Your Answer:*__  The autoencoder main usages are for dimensionality reduction and denoising. Compressing images is useful for reverse image searches as well. Recreating inputs from a compression is useful for feature extraction. Comparing the decoded output to the input shows how much the model knows about the input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "  \n",
        "  Linear regression and decision trees, because they have high explainability, and can be run quickly\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "\n",
        "  Reproducibility, containerization, and packaging I think will be useful for the workplace\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "\n",
        "  Continue the trend of misuse and abuse. Big data and being more commonplace among medium sized companies\n",
        "\n",
        "- What are the threats posed by AI to our society?\n",
        "  \n",
        "  When people can't distinguish between AI created content and people, the general worldview can be easily manipulated. Thus, democracy can be tainted. For example, during the net neutrality issues (ongoing) millions of comments in support of letting ISPs throttle and monetize sectors of the internet surfaced. NO ONE but people on the ISPs payroll would benefit, Ajit Pai. \n",
        "\n",
        "- How do you think we can counteract those threats? \n",
        "\n",
        "  Educate the general  public about the deceit, trace the source of the crimes against democracy, and punish severely.\n",
        "\n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "\n",
        "  I'm more swayed by the notion of Comprehensive AI Services (CAIS), where if human intelligence level is just one more capability away, that can be managed by another AI. Imagine an AI that can just lookup the latest and greatest at tensorflow hub, and another that manages its implementation. The line separating humanity and artificial creation will be blurred, especially with neural link.\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5_xjd0lt7k5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "ab891989-54de-41aa-9a61-3a1861f5a012"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    }
  ]
}